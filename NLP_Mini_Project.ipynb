{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listening.....\n",
      "Recognizing.....\n",
      "user said आपको पता चला कि आप क्या कर रहे थे अगर आपको पता नहीं चला आप क्या कर रहे थे तो आपको पता ही नहीं आप क्या कर रहे हो आपको पता करने के लिए आपको पता करना होगा क्या\n",
      "\n",
      "Enter the language in which you want to convert     : Ex. Hindi , English , etc.\n",
      "\n",
      "listening.....\n",
      "Recognizing.....\n",
      "say that again please.....\n",
      "listening.....\n",
      "Recognizing.....\n",
      "user said इंग्लिश इंग्लिश\n",
      "\n",
      "Language in which you are trying to convert    is currently not available ,please input some other language\n",
      "\n",
      "Enter the language in which you want to convert     : Ex. Hindi , English , etc.\n",
      "\n",
      "listening.....\n",
      "Recognizing.....\n",
      "user said इंग्लिश\n",
      "\n",
      "C:\\Users\\katka/natural_language_toolkit_data\n",
      "b\"You found out what you were doing If you didn't know what you were doing You didn't know what you were doing To know you had to know what\"\n",
      "You found out what you were doing If you didn't know what you were doing You didn't know what you were doing To know you had to know what\n"
     ]
    }
   ],
   "source": [
    "from playsound import playsound\n",
    "import speech_recognition as sr\n",
    "from googletrans import Translator\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import nltk.data\n",
    "\n",
    "\n",
    "\n",
    "dic=('हिंदी','hi','ગુજરાતી','gu','मराठी','mr','इंग्लिश','en')\n",
    "\n",
    "x=int(input(\"Type 1 for English,2 for Hindi,3 for gujarati,4 for punjabi,5 for marathi: \"))\n",
    "if(x==1):\n",
    "    language_code='en'\n",
    "elif x==2:\n",
    "    language_code='hi-IN'\n",
    "elif x==3:\n",
    "    language_code='gu'\n",
    "elif x==4:\n",
    "    language_code='pa-guru-IN'\n",
    "else:\n",
    "    language_code='mr-IN'\n",
    "\n",
    "\n",
    "def takecommand():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"listening.....\")\n",
    "        r.pause_threshold = 1\n",
    "        audio = r.listen(source,phrase_time_limit=60)\n",
    "\n",
    "    try:\n",
    "        print(\"Recognizing.....\")\n",
    "        query = r.recognize_google(audio, language=language_code)\n",
    "        print(f\"user said {query}\\n\")\n",
    "    except Exception as e:\n",
    "        print(\"say that again please.....\")\n",
    "        return \"None\"\n",
    "    return query\n",
    "\n",
    "def takecommand_convert():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"listening.....\")\n",
    "        r.pause_threshold = 1\n",
    "        audio = r.listen(source,phrase_time_limit=5)\n",
    "\n",
    "    try:\n",
    "        print(\"Recognizing.....\")\n",
    "        query = r.recognize_google(audio, language=language_code)\n",
    "        print(f\"user said {query}\\n\")\n",
    "    except Exception as e:\n",
    "        print(\"say that again please.....\")\n",
    "        return \"None\"\n",
    "    return query\n",
    "\n",
    "\n",
    "query = takecommand()\n",
    "while (query == \"None\"):\n",
    "    query = takecommand()\n",
    "\n",
    "\n",
    "def destination_language():\n",
    "    print(\"Enter the language in which you want to convert \\\n",
    "    : Ex. Hindi , English , etc.\")\n",
    "    print()\n",
    "\n",
    "    # Input destination language in which the user\n",
    "    # wants to translate\n",
    "    to_lang = takecommand_convert()\n",
    "    while (to_lang == \"None\"):\n",
    "        to_lang = takecommand_convert()\n",
    "    to_lang = to_lang.lower()\n",
    "    return to_lang\n",
    "\n",
    "\n",
    "to_lang = destination_language()\n",
    "\n",
    "# Mapping it with the code\n",
    "while (to_lang not in dic):\n",
    "    print(\"Language in which you are trying to convert\\\n",
    "    is currently not available ,please input some other language\")\n",
    "    print()\n",
    "    to_lang = destination_language()\n",
    "\n",
    "to_lang = dic[dic.index(to_lang) + 1]\n",
    "translator = Translator()\n",
    "\n",
    "\n",
    "translation = translator.translate(query,dest='en')\n",
    "text = translation.text\n",
    "speech_translation=text\n",
    "speak = gTTS(text=text, lang=to_lang, slow=False)\n",
    "\n",
    "# Using save() method to save the translated\n",
    "# speech in capture_voice.mp3\n",
    "speak.save(\"captured_voice.mp3\")\n",
    "\n",
    "text1=speak.text\n",
    "\n",
    "path = os.path.expanduser('~/natural_language_toolkit_data')\n",
    "print(path)\n",
    "if not os.path.exists(path):\n",
    "   os.mkdir(path)\n",
    "\n",
    "path in nltk.data.path\n",
    "\n",
    "\n",
    "with open(os.path.expanduser('~/natural_language_toolkit_data/wordfile.txt'),'w',encoding = 'utf-8') as f:\n",
    "   f.write(text1)\n",
    "\n",
    "\n",
    "t=os.path.expanduser('file://C://Users//Katka//natural_language_toolkit_data//wordfile.txt')\n",
    "\n",
    "lm=nltk.data.load(t, format=\"raw\")\n",
    "print(lm)\n",
    "# Using OS module to run the translated voice.\n",
    "playsound('captured_voice.mp3')\n",
    "os.remove('captured_voice.mp3')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitle=text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BART for Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "input_tensor = tokenizer.encode(subtitle, return_tensors=\"pt\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     0,  1185,   303,    66,    99,    47,    58,   608,   318,\n",
       "            47,   399,    75,   216,    99,    47, 18258,   608,   370,   399,\n",
       "            75, 27066,    99,    47, 43822,   608,     4,   598,   216,    47,\n",
       "            56,     7,   216,    99,     7,   109,     4,   370,    56,     7,\n",
       "            28,   441,     7,   109,    24,     4,   598,   109,    24,   157,\n",
       "             6,    47,    33,     7,   216,   141,     4,   370,   531,   216,\n",
       "           141,     7,   109,    99,    47,   214,   608,     4,   318,    47,\n",
       "           218,    75,     6,    47,   214,    45,   608,    24,   235,     4,\n",
       "           370,   214,   608,    24,  1593,     4,   370,    64,    75,   109,\n",
       "            24,   235,   114,    47,   214,  6023,     4,   370,    33,     7,\n",
       "            28,  3230,     4,   370,   348,   300,     7,    28,   686,     9,\n",
       "            99,    47,    32,   608,     4,   370,   218,    75,   236,     7,\n",
       "           109,   932,    47,   214,  8265,     9,     4,     2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_tensor = model.generate(input_tensor, max_length=160, min_length=120, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "outputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=tokenizer.decode(outputs_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text=\"Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning. In reinforcement learning methods, expectations are approximated by averaging over samples and using function approximation techniques to cope with the need to represent value functions over large state-action spaces. Policy iteration consists of two steps: policy evaluation and policy improvement. The work on learning ATARI games by Google DeepMind increased attention to deep reinforcement learning or end-to-end reinforcement learning. Assuming full knowledge of the MDP, the two basic approaches to compute the optimal action-value function are value iteration and policy iteration. Two elements make reinforcement learning powerful: the use of samples to optimize performance and the use of function approximation to deal with large environments. Many policy search methods may get stuck in local optima (as they are based on local search)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the length of the text is greater than 20, take a 10th of the sentences\n",
    "if text.count(\". \") > 20:\n",
    "  length = int(round(text.count(\". \")/10, 0))\n",
    "# Otherwise return five sentences\n",
    "else:\n",
    "  length = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "nopunc = [char for char in text if char not in string.punctuation]\n",
    "nopunc = ''.join(nopunc)\n",
    "# Remove stopwords\n",
    "processed_text =[word for word in nopunc.split() if word.lower() not in nltk.corpus.stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store word frequency\n",
    "word_freq = {}\n",
    "# Enter each word and its number of occurrences\n",
    "for word in processed_text:\n",
    "  if word not in word_freq:\n",
    "    word_freq[word] = 1\n",
    "  else:\n",
    "    word_freq[word] = word_freq[word] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide all frequencies by max frequency to give store of (0, 1]\n",
    "max_freq = max(word_freq.values())\n",
    "for word in word_freq.keys():\n",
    "  word_freq[word] = (word_freq[word]/max_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the sentences in the text\n",
    "sent_list = nltk.sent_tokenize(text)\n",
    "# Create an empty dictionary to store sentence scores\n",
    "sent_score = {}\n",
    "for sent in sent_list:\n",
    "  for word in nltk.word_tokenize(sent.lower()):\n",
    "    if word in word_freq.keys():\n",
    "      if sent not in sent_score.keys():\n",
    "        sent_score[sent] = word_freq[word]\n",
    "      else:\n",
    "        sent_score[sent] = sent_score[sent] + word_freq[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You found out what you were doing If you didn't know what you were doing You didn't know what you were doing To know you had to know what\n"
     ]
    }
   ],
   "source": [
    "summary_sents = nlargest(length, sent_score, key = sent_score.get)\n",
    "summary = ' '.join(summary_sents)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the language in which you want to convert #     : Ex. Hindi ,Gujarati,Marathi etc.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid destination language",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 35\u001b[0m\n\u001b[0;32m     30\u001b[0m     language_code\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmr\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     32\u001b[0m translator \u001b[39m=\u001b[39m Translator()\n\u001b[1;32m---> 35\u001b[0m translation \u001b[39m=\u001b[39m translator\u001b[39m.\u001b[39;49mtranslate(summary,dest\u001b[39m=\u001b[39;49mlanguage_code)\n\u001b[0;32m     36\u001b[0m text \u001b[39m=\u001b[39m translation\u001b[39m.\u001b[39mtext\n\u001b[0;32m     37\u001b[0m \u001b[39mprint\u001b[39m(text)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\googletrans\\client.py:200\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[1;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m         dest \u001b[39m=\u001b[39m LANGCODES[dest]\n\u001b[0;32m    199\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39minvalid destination language\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    203\u001b[0m     result \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: invalid destination language"
     ]
    }
   ],
   "source": [
    "dic=('हिंदी','hi-IN','ગુજરાતી','gu-IN','मराठी','mr')\n",
    "\n",
    "# def destination_language():\n",
    "#     print(\"Enter the language in which you want to convert \\\n",
    "#     : Ex. Hindi ,Gujarati,Marathi etc.\")\n",
    "#     print()\n",
    "\n",
    "#     # Input destination language in which the user\n",
    "#     # wants to translate\n",
    "#     to_lang = takecommand()\n",
    "#     while (to_lang == \"None\"):\n",
    "#         to_lang = takecommand()\n",
    "#     to_lang = to_lang.lower()\n",
    "#     return to_lang\n",
    "\n",
    "\n",
    "# to_lang = destination_language()\n",
    "print(\"Enter the language in which you want to convert \\\n",
    "#     : Ex. Hindi ,Gujarati,Marathi etc.\")\n",
    "print()\n",
    "\n",
    "x=int(input(\"Type 1 for Hindi,2 for gujarati,3 for punjabi,4 for marathi: \"))\n",
    "if(x==1):\n",
    "    language_code='hi-IN'\n",
    "elif x==2:\n",
    "    language_code='gu'\n",
    "elif x==3:\n",
    "    language_code='pa-guru'\n",
    "elif x==4:\n",
    "    language_code='mr'\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "\n",
    "translation = translator.translate(summary,dest=language_code)\n",
    "text = translation.text\n",
    "print(text)\n",
    "speak = gTTS(text=text, lang=to_lang, slow=False)\n",
    "\n",
    "# Using save() method to save the translated\n",
    "# speech in capture_voice.mp3\n",
    "speak.save(\"captured_voice.mp3\")\n",
    "\n",
    "text1=speak.text\n",
    "playsound('captured_voice.mp3')\n",
    "os.remove('captured_voice.mp3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
